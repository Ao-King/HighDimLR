{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "条件数: 13813.935705304106\n"
     ]
    }
   ],
   "source": [
    "# 生成随机矩阵X_n\n",
    "np.random.seed(24)\n",
    "n = 1000    # 样本量\n",
    "p = 1000    # 变量数\n",
    "\n",
    "# 创建协方差矩阵\n",
    "cov_matrix = np.full((p, p), 0.5)  # 创建一个所有元素都是 0.5 的矩阵\n",
    "np.fill_diagonal(cov_matrix, 2.0)  # 将对角线元素设置为 2.0\n",
    "\n",
    "mean_vector                = np.zeros(p)  # 均值向量\n",
    "X                          = np.random.multivariate_normal(mean_vector, cov_matrix, n)\n",
    "# 奇异值分解\n",
    "U, S, Vt = np.linalg.svd(X)\n",
    "\n",
    "# 计算条件数\n",
    "condition_number = S[0] / S[-1]\n",
    "print(\"条件数:\", condition_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.769851930898774\n"
     ]
    }
   ],
   "source": [
    "# 定义β向量\n",
    "np.random.seed(24)\n",
    "beta = beta = np.random.uniform(low=-2, high=2, size=p)  \n",
    "print(np.linalg.norm(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.08628983078468\n"
     ]
    }
   ],
   "source": [
    "# 生成均值为0方差为4的n维向量en\n",
    "np.random.seed(24)\n",
    "mean    = 0  # 均值\n",
    "std_dev = 2  # 标准差，方差为标准差的平方，即4\n",
    "\n",
    "# 生成向量\n",
    "e = np.random.normal(mean, std_dev, n)\n",
    "norm_e = np.linalg.norm(e)\n",
    "Y = np.dot(X, beta) + e\n",
    "print(norm_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau   = 0.6\n",
    "delta = tau*norm_e\n",
    "s1, s2 = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.21716376506137\n",
      "1.9527028497497607e-13\n"
     ]
    }
   ],
   "source": [
    "# 最小二乘法\n",
    "def least_square(X, Y):\n",
    "    beta = np.linalg.lstsq(X, Y, rcond=None)[0]\n",
    "    return beta\n",
    "beta_LS = least_square(X, Y)\n",
    "norm_LS = np.linalg.norm(beta_LS - beta)\n",
    "print(norm_LS)\n",
    "sigma_LS = np.linalg.norm(Y - np.dot(X, beta_LS))\n",
    "sigma_LS = sigma_LS / np.sqrt(s2)\n",
    "print(sigma_LS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小的 norm_cut: 7.742594886638292, 对应的 k: 975\n"
     ]
    }
   ],
   "source": [
    "# 奇异值分解\n",
    "U, S, Vt = np.linalg.svd(X)\n",
    "\n",
    "# 定义一个函数来计算 norm_cut\n",
    "def compute_norm_cut(k):\n",
    "    # 截断奇异值\n",
    "    S_truncated = np.zeros_like(S)\n",
    "    S_truncated[:k] = S[:k]\n",
    "\n",
    "    # 构造截断后的矩阵\n",
    "    Sigma_truncated = np.zeros((U.shape[0], Vt.shape[0]))\n",
    "    np.fill_diagonal(Sigma_truncated, S_truncated)\n",
    "\n",
    "    # 计算 S_cut 和 S_inv\n",
    "    S_cut = Sigma_truncated.T @ Sigma_truncated\n",
    "    S_inv = np.zeros_like(S_cut)\n",
    "    S_inv[S_cut != 0] = 1 / S_cut[S_cut != 0]\n",
    "\n",
    "    # 计算 beta_cut\n",
    "    beta_cut = Vt.T @ S_inv @ Vt @ X.T @ Y\n",
    "\n",
    "    # 计算 norm_cut\n",
    "    norm_cut = np.linalg.norm(beta_cut - beta)\n",
    "    \n",
    "    return norm_cut, k\n",
    "\n",
    "# 使用Parallel和delayed并行处理\n",
    "results = Parallel(n_jobs=-1)(delayed(compute_norm_cut)(k) for k in range(1000, 0, -1))\n",
    "\n",
    "# 找到最小的 norm_cut 及其对应的 k 值\n",
    "min_norm_cut, best_k = min(results, key=lambda x: x[0])\n",
    "\n",
    "# 输出最小的 norm_cut 及其对应的 k 值\n",
    "print(f\"最小的 norm_cut: {min_norm_cut}, 对应的 k: {best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.7425948866382885 9.979738573636704\n",
      "0.4371615884471287\n",
      "9.786581385402235\n"
     ]
    }
   ],
   "source": [
    "# Spectral cut-off regression\n",
    "\n",
    "# 选择截断点\n",
    "k = best_k  # 截断点，可以根据需要调整\n",
    "\n",
    "# 截断奇异值\n",
    "S_truncated = np.zeros_like(S)\n",
    "S_truncated[:k] = S[:k]\n",
    "\n",
    "# 构造截断后的矩阵\n",
    "Sigma = np.zeros((U.shape[0], Vt.shape[0]))\n",
    "Sigma_truncated = np.zeros((U.shape[0], Vt.shape[0]))\n",
    "np.fill_diagonal(Sigma, S)\n",
    "np.fill_diagonal(Sigma_truncated, S_truncated)\n",
    "X_truncated = U @ Sigma_truncated @ Vt\n",
    "S_cut = Sigma_truncated.T@Sigma_truncated\n",
    "S_inv = np.zeros_like(S_cut)\n",
    "S_inv[S_cut != 0] = 1 / S_cut[S_cut != 0]\n",
    "beta_cut = Vt.T @ S_inv @ Vt @ X.T @ Y\n",
    "norm_cut = np.linalg.norm(beta_cut - beta)\n",
    "I = np.eye(s2)\n",
    "beta_cut_debias =(2*I -Sigma.T@ Sigma @ S_inv) @ beta_cut\n",
    "norm_cut_debias = np.linalg.norm(beta_cut_debias - beta)\n",
    "print(norm_cut, norm_cut_debias)\n",
    "sigma_cut = np.linalg.norm(Y - X @ beta_cut)\n",
    "sigma_cut = sigma_cut / np.sqrt(s2)\n",
    "print(sigma_cut)\n",
    "sigma_cut_debias = np.linalg.norm(Y - X @ beta_cut_debias)\n",
    "sigma_cut_debias = sigma_cut_debias / np.sqrt(s2)\n",
    "print(sigma_cut_debias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of the first element in mse_list that is smaller than delta is: 3247\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "C = 50000\n",
    "m = 10\n",
    "def compute_mse(c, X, Y):\n",
    "    alpha = c / s1\n",
    "    I = np.eye(s2)\n",
    "    beta_r = np.linalg.inv(X.T @ X + alpha * I) @ X.T @ Y\n",
    "    mse = np.linalg.norm(Y - X @ beta_r)\n",
    "    # mse = np.linalg.norm(beta_r - beta)\n",
    "    return mse\n",
    "\n",
    "# 假设 X, Y, C 已经定义\n",
    "mse_list = Parallel(n_jobs=-1)(delayed(compute_mse)(c, X, Y) for c in range(C+1, 0, -m))\n",
    "mse_index = np.where(mse_list < delta)[0][0]\n",
    "print(\"The index of the first element in mse_list that is smaller than delta is:\", mse_index)\n",
    "\n",
    "alpha_R = C- mse_index*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.286667241485326 32.2905418150533\n",
      "37.81396981014561\n",
      "33.06539038375877\n"
     ]
    }
   ],
   "source": [
    "# 岭回归\n",
    "def ridge(X, Y, C):\n",
    "    alpha  = C\n",
    "    I      = np.eye(s2)\n",
    "    gen    = np.linalg.inv(X.T @ X + alpha*I) @ X.T\n",
    "    beta   = gen @ Y\n",
    "    beta_debias = (I + alpha*np.linalg.inv(X.T @ X + alpha*I))@beta\n",
    "    return beta, beta_debias\n",
    "\n",
    "beta_Ridge, beta_Ridge_debias = ridge(X, Y, alpha_R)\n",
    "norm_Ridge = np.linalg.norm(beta_Ridge - beta)\n",
    "norm_Ridge_debias = np.linalg.norm(beta_Ridge_debias - beta)\n",
    "print(norm_Ridge, norm_Ridge_debias)\n",
    "sigma_Ridge = np.linalg.norm(Y - np.dot(X, beta_Ridge))\n",
    "sigma_Ridge = sigma_Ridge / np.sqrt(s2)\n",
    "print(sigma_Ridge)\n",
    "sigma_Ridge_debias = np.linalg.norm(Y - np.dot(X, beta_Ridge_debias))\n",
    "sigma_Ridge_debias = sigma_Ridge_debias / np.sqrt(s2)\n",
    "print(sigma_Ridge_debias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of the first element in mse_list that is smaller than delta is: 1993\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "C = 2000\n",
    "m = 1\n",
    "def compute_mse(c, X, Y):\n",
    "    alpha = c / s1\n",
    "    lasso =  Lasso(alpha=alpha)\n",
    "    lasso.fit(X, Y)\n",
    "    beta_lasso = lasso.coef_\n",
    "    mse = np.linalg.norm(Y - X @ beta_lasso)\n",
    "    return mse\n",
    "\n",
    "# 假设 X, Y, C 已经定义\n",
    "mse_list = Parallel(n_jobs=-1)(delayed(compute_mse)(c, X, Y) for c in range(C+1, 0, -m))\n",
    "mse_index = np.where(mse_list < delta)[0][0]\n",
    "print(\"The index of the first element in mse_list that is smaller than delta is:\", mse_index)\n",
    "best_c = C - mse_index*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.90069892999486\n",
      "40.777114995545276\n"
     ]
    }
   ],
   "source": [
    "lasso =  Lasso(alpha=best_c)\n",
    "lasso.fit(X, Y)\n",
    "beta_lasso = lasso.coef_\n",
    "norm_Lasso = np.linalg.norm(beta_lasso - beta)\n",
    "print(norm_Lasso)\n",
    "sigma_Lasso = np.linalg.norm(Y - np.dot(X, beta_lasso))\n",
    "sigma_Lasso = sigma_Lasso / np.sqrt(s2)\n",
    "print(sigma_Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.382442936303862 7482 8.772960815107623\n",
      "1.2160315220472528\n",
      "0.801895367818072\n"
     ]
    }
   ],
   "source": [
    "# Landweber回归\n",
    "t        = 3e-6    # 步长\n",
    "max_iter = 100000   # 最大迭代次数\n",
    "\n",
    "def landweber(X, Y, t, max_iter):\n",
    "    s = X.shape\n",
    "    m = s[1]\n",
    "    beta_cur = np.zeros(m)\n",
    "    for k in range(1, max_iter):\n",
    "        beta_prev = beta_cur\n",
    "        beta_cur = beta_prev + t * np.dot(X.T, (Y - np.dot(X, beta_prev)))\n",
    "        if np.linalg.norm(Y - np.dot(X, beta_cur)) <= delta:\n",
    "            break\n",
    "    return beta_prev, k-1\n",
    "def landweber_debias(X, Y, t, max_iter):\n",
    "    s = X.shape\n",
    "    m = s[1]\n",
    "    beta_cur = np.zeros(m)\n",
    "    for k in range(1, max_iter+1):\n",
    "        beta_prev = beta_cur\n",
    "        beta_cur = beta_prev + t * np.dot(X.T, (Y - np.dot(X, beta_prev)))\n",
    "        if k == max_iter:\n",
    "            break\n",
    "    return beta_cur\n",
    "beta_Landweber, k_Landweber = landweber(X, Y, t, max_iter)\n",
    "beta_Landweber_debias = landweber_debias(X, Y, t, 2*k_Landweber)\n",
    "norm_Landweber    = np.linalg.norm(beta_Landweber - beta)\n",
    "norm_Landweber_debias  = np.linalg.norm(beta_Landweber_debias - beta)  \n",
    "\n",
    "print(norm_Landweber, k_Landweber, norm_Landweber_debias)\n",
    "sigma_Landeweber = np.linalg.norm(Y - np.dot(X, beta_Landweber))\n",
    "sigma_Landeweber = sigma_Landeweber / np.sqrt(s2)\n",
    "print(sigma_Landeweber)\n",
    "sigma_Landeweber_debias = np.linalg.norm(Y - np.dot(X, beta_Landweber_debias))\n",
    "sigma_Landeweber_debias = sigma_Landeweber_debias / np.sqrt(s2)\n",
    "print(sigma_Landeweber_debias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.381879066206073 7484 8.772444841108381\n",
      "1.2158904031556519\n",
      "0.8017865660858023\n"
     ]
    }
   ],
   "source": [
    "# Showalter回归\n",
    "t        = 3e-6    # 步长\n",
    "max_iter = 100000   # 最大迭代次数\n",
    "\n",
    "def showalter(X, Y, t, max_iter):\n",
    "    s = X.shape\n",
    "    m = s[1]\n",
    "    beta_cur = np.zeros(m)\n",
    "    Z1 = np.dot(X.T, Y)\n",
    "    Z2 = np.dot(X.T, X)\n",
    "    for k in range(1, max_iter):\n",
    "        beta_prev = beta_cur\n",
    "        K1 = Z1 - np.dot(Z2, beta_prev)\n",
    "        K2 = Z1 - np.dot(Z2, (beta_prev + 0.5 * t * K1))\n",
    "        K3 = Z1 - np.dot(Z2, (beta_prev + 0.5 * t * K2))\n",
    "        K4 = Z1 - np.dot(Z2, (beta_prev + t * K3))\n",
    "        beta_cur = beta_prev + t / 6 * (K1 + 2 * K2 + 2 * K3 + K4)\n",
    "        # print(np.linalg.norm(Y - np.dot(X, beta_cur)))\n",
    "        # if np.linalg.norm(beta_cur - beta_prev) <= 1e-4:\n",
    "        if np.linalg.norm(Y - np.dot(X, beta_cur)) <= delta:\n",
    "            break\n",
    "    return beta_cur, k\n",
    "def showalter_debias(X, Y, t, max_iter):\n",
    "    s = X.shape\n",
    "    m = s[1]\n",
    "    beta_cur = np.zeros(m)\n",
    "    Z1 = np.dot(X.T, Y)\n",
    "    Z2 = np.dot(X.T, X)\n",
    "    for k in range(1, max_iter+1):\n",
    "        beta_prev = beta_cur\n",
    "        K1 = Z1 - np.dot(Z2, beta_prev)\n",
    "        K2 = Z1 - np.dot(Z2, (beta_prev + 0.5 * t * K1))\n",
    "        K3 = Z1 - np.dot(Z2, (beta_prev + 0.5 * t * K2))\n",
    "        K4 = Z1 - np.dot(Z2, (beta_prev + t * K3))\n",
    "        beta_cur = beta_prev + t / 6 * (K1 + 2 * K2 + 2 * K3 + K4)\n",
    "        if k == max_iter:\n",
    "            break\n",
    "    return beta_cur\n",
    "beta_showalter, k_showalter = showalter(X, Y, t, max_iter)\n",
    "beta_showalter_debias = showalter_debias(X, X@beta_showalter, t, k_showalter)\n",
    "beta_showalter_debias = 2*beta_showalter-beta_showalter_debias\n",
    "norm_showalter = np.linalg.norm(beta_showalter - beta)\n",
    "norm_showalter_debias = np.linalg.norm(beta_showalter_debias - beta)\n",
    "print(norm_showalter, k_showalter, norm_showalter_debias)\n",
    "sigma_showalter = np.linalg.norm(Y - np.dot(X, beta_showalter))\n",
    "sigma_showalter = sigma_showalter / np.sqrt(s2)\n",
    "print(sigma_showalter)\n",
    "sigma_showalter_debias = np.linalg.norm(Y - np.dot(X, beta_showalter_debias))\n",
    "sigma_showalter_debias = sigma_showalter_debias / np.sqrt(s2)\n",
    "print(sigma_showalter_debias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.9123300130305925 2611 7.05516776416651\n",
      "1.21577792168792\n",
      "0.2854187896604149\n"
     ]
    }
   ],
   "source": [
    "# HBF回归\n",
    "t        = 5e-4    # 步长\n",
    "max_iter = 100000   # 最大迭代次数\n",
    "\n",
    "def hbf(X, Y, t, max_iter):\n",
    "    s = X.shape\n",
    "    m = s[1]\n",
    "    eta = 5\n",
    "\n",
    "    A11 = np.zeros((m, m))\n",
    "    A12 = np.eye(m)\n",
    "    A21 = -np.dot(X.T, X)\n",
    "    A22 = -eta * np.eye(m)\n",
    "    A = np.vstack((np.hstack((A11, A12)), np.hstack((A21, A22))))\n",
    "    b = np.hstack((np.zeros(m), np.dot(X.T, Y)))\n",
    "    z = np.zeros(2 * m)\n",
    "\n",
    "    for k in range(1, max_iter):\n",
    "        K1 = np.dot(A, z) + b\n",
    "        K2 = np.dot(A, (z + 0.5 * t * K1)) + b\n",
    "        K3 = np.dot(A, (z + 0.5 * t * K2)) + b\n",
    "        K4 = np.dot(A, (z + t * K3)) + b\n",
    "        z = z + t / 6 * (K1 + 2 * K2 + 2 * K3 + K4)\n",
    "        beta_cur = z[:m]\n",
    "        # print(np.linalg.norm(Y - np.dot(X, beta_cur)))\n",
    "        if np.linalg.norm(Y - np.dot(X, beta_cur)) <= delta:\n",
    "            break\n",
    "    return beta_cur, k\n",
    "\n",
    "def hbf_debias(X, Y, t, max_iter):\n",
    "    s = X.shape\n",
    "    m = s[1]\n",
    "    eta = 5\n",
    "\n",
    "    A11 = np.zeros((m, m))\n",
    "    A12 = np.eye(m)\n",
    "    A21 = -np.dot(X.T, X)\n",
    "    A22 = -eta * np.eye(m)\n",
    "    A = np.vstack((np.hstack((A11, A12)), np.hstack((A21, A22))))\n",
    "    b = np.hstack((np.zeros(m), np.dot(X.T, Y)))\n",
    "    z = np.zeros(2 * m)\n",
    "\n",
    "    for k in range(1, max_iter+1):\n",
    "        K1 = np.dot(A, z) + b\n",
    "        K2 = np.dot(A, (z + 0.5 * t * K1)) + b\n",
    "        K3 = np.dot(A, (z + 0.5 * t * K2)) + b\n",
    "        K4 = np.dot(A, (z + t * K3)) + b\n",
    "        z = z + t / 6 * (K1 + 2 * K2 + 2 * K3 + K4)\n",
    "        beta_cur = z[:m]\n",
    "        if k == max_iter:\n",
    "            break\n",
    "    return beta_cur\n",
    "beta_hbf, k_hbf = hbf(X, Y, t, max_iter)\n",
    "beta_hbf_debias = hbf_debias(X, X@beta_hbf, t, k_hbf)\n",
    "beta_hbf_debias = 2*beta_hbf - beta_hbf_debias\n",
    "norm_hbf = np.linalg.norm(beta_hbf - beta)\n",
    "norm_hbf_debias = np.linalg.norm(beta_hbf_debias - beta)\n",
    "print(norm_hbf, k_hbf, norm_hbf_debias)\n",
    "sigma_hbf = np.linalg.norm(Y - np.dot(X, beta_hbf))\n",
    "sigma_hbf = sigma_hbf / np.sqrt(s2)\n",
    "print(sigma_hbf)\n",
    "sigma_hbf_debias = np.linalg.norm(Y - np.dot(X, beta_hbf_debias))\n",
    "sigma_hbf_debias = sigma_hbf_debias / np.sqrt(s2)\n",
    "print(sigma_hbf_debias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.323429163379837 589 8.705441366222267\n",
      "1.2144461385081629\n",
      "0.7731337964345714\n"
     ]
    }
   ],
   "source": [
    "# Acceleration regression of order kappa\n",
    "t        = 5e-5   # 步长\n",
    "max_iter = 100000   # 最大迭代次数\n",
    "kappa    = 0.5       # 加速阶数\n",
    "\n",
    "def ARk(X, Y, t, k_max):\n",
    "    s = X.shape\n",
    "    m = s[1]\n",
    "    beta_prev = np.zeros(m)\n",
    "    I      = np.eye(m)\n",
    "    v_prev = np.zeros(m)\n",
    "    for k in range(1, k_max):\n",
    "        beta_cur = beta_prev + k*t*v_prev\n",
    "        D = np.linalg.inv((t*(k*t)**kappa)*X.T @ X + I + (((k*t)**(-kappa))-kappa)/k*I)\n",
    "        v_cur = D@v_prev+ t*D@np.dot(X.T, (Y - np.dot(X, beta_prev)))\n",
    "        beta_prev = beta_cur\n",
    "        v_prev = v_cur\n",
    "        if np.linalg.norm(Y - np.dot(X, beta_prev)) <= delta:\n",
    "            break\n",
    "    return beta_cur, k\n",
    "\n",
    "def ARk_debias(X, Y, t, k_max):\n",
    "    s = X.shape\n",
    "    m = s[1]\n",
    "    beta_prev = np.zeros(m)\n",
    "    I      = np.eye(m)\n",
    "    v_prev = np.zeros(m)\n",
    "    for k in range(1, k_max+1):\n",
    "        beta_cur = beta_prev + k*t*v_prev\n",
    "        D = np.linalg.inv((t*(k*t)**kappa)*X.T @ X + I + (((k*t)**(-kappa))-kappa)/k*I)\n",
    "        v_cur = D@v_prev+t*D@np.dot(X.T, (Y - np.dot(X, beta_prev)))\n",
    "        beta_prev = beta_cur\n",
    "        v_prev = v_cur\n",
    "        if k == max_iter:\n",
    "            break\n",
    "    return beta_cur    \n",
    "\n",
    "beta_ARk, k_ARk = ARk(X, Y, t, max_iter)\n",
    "beta_ARk_debias = ARk_debias(X, X@beta_ARk, t, k_ARk)\n",
    "beta_ARk_debias = 2*beta_ARk - beta_ARk_debias\n",
    "norm_ARk = np.linalg.norm(beta_ARk - beta)\n",
    "norm_ARk_debias = np.linalg.norm(beta_ARk_debias - beta)\n",
    "print(norm_ARk, k_ARk, norm_ARk_debias)\n",
    "sigma_ARk = np.linalg.norm(Y - np.dot(X, beta_ARk))\n",
    "sigma_ARk = sigma_ARk / np.sqrt(s2)\n",
    "print(sigma_ARk)\n",
    "sigma_ARk_debias = np.linalg.norm(Y - np.dot(X, beta_ARk_debias))\n",
    "sigma_ARk_debias = sigma_ARk_debias / np.sqrt(s2)\n",
    "print(sigma_ARk_debias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.18047240971472 1225 7.053008231586591\n",
      "1.215210434877124\n",
      "0.45624264504166984\n"
     ]
    }
   ],
   "source": [
    "# 二阶渐进回归\n",
    "t        = 5e-4    # 步长\n",
    "max_iter = 100000   # 最大迭代次数\n",
    "\n",
    "def second(X, Y, t, k_max):\n",
    "    r = X.shape\n",
    "    m = r[1]\n",
    "    s = 0.5\n",
    "    beta_cur = np.zeros(m)\n",
    "    v_cur    = np.zeros(m)\n",
    "    q_cur    = np.zeros(m)\n",
    "    for k in range(1, k_max):\n",
    "        p        =  2*k/(2*k+2*s+1)\n",
    "        q_half   =  p*q_cur + p*(t / 2) * np.dot(X.T, (Y - np.dot(X, beta_cur))) \n",
    "        beta_cur = beta_cur + t * q_half\n",
    "        a        = (2*k-2*s+1)*(k+1)/(2*k+2*s+3)/k\n",
    "        v_cur   =  beta_cur + 2*t*a*q_half\n",
    "        q_cur    =  (2*k+1-2*s)/(2*k+2)*q_half +(t / 2) * np.dot(X.T, (Y - np.dot(X, v_cur))) \n",
    "        if np.linalg.norm(Y - np.dot(X, beta_cur)) <= delta:\n",
    "            break\n",
    "    return beta_cur, k\n",
    "\n",
    "def second_debias(X, Y, t, k_max):\n",
    "    r = X.shape\n",
    "    m = r[1]\n",
    "    s = 0.5\n",
    "    beta_cur = np.zeros(m)\n",
    "    v_cur    = np.zeros(m)\n",
    "    q_cur    = np.zeros(m)\n",
    "\n",
    "    for k in range(1, k_max+1):\n",
    "        p        =  2*k/(2*k+2*s+1)\n",
    "        q_half   =  p*q_cur + p*(t / 2) * np.dot(X.T, (Y - np.dot(X, beta_cur))) \n",
    "        beta_cur = beta_cur + t * q_half\n",
    "        a        = (2*k-2*s+1)*(k+1)/(2*k+2*s+3)/k\n",
    "        v_cur   =  beta_cur + 2*t*a*q_half\n",
    "        q_cur    =  (2*k+1-2*s)/(2*k+2)*q_half +(t / 2) * np.dot(X.T, (Y - np.dot(X, v_cur))) \n",
    "        if k == k_max:\n",
    "            break\n",
    "    return beta_cur\n",
    "\n",
    "beta_second, k_second = second(X, Y, t, max_iter)\n",
    "beta_second_debias = second_debias(X, X@beta_second, t, k_second)\n",
    "beta_second_debias = 2*beta_second - beta_second_debias\n",
    "norm_second = np.linalg.norm(beta_second - beta)\n",
    "norm_second_debias = np.linalg.norm(beta_second_debias - beta)\n",
    "print(norm_second, k_second, norm_second_debias)\n",
    "sigma_second = np.linalg.norm(Y - np.dot(X, beta_second))\n",
    "sigma_second = sigma_second / np.sqrt(s2)\n",
    "print(sigma_second)\n",
    "sigma_second_debias = np.linalg.norm(Y - np.dot(X, beta_second_debias))\n",
    "sigma_second_debias = sigma_second_debias / np.sqrt(s2)\n",
    "print(sigma_second_debias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.382111939423234 7484 8.772733259138672\n",
      "1.2159326923422151\n",
      "0.80186069999375\n"
     ]
    }
   ],
   "source": [
    "# Nesterov回归\n",
    "t        = 3e-6    # 步长\n",
    "max_iter = 100000   # 最大迭代次数\n",
    "omega    = 3       # omega  \n",
    "\n",
    "def Nesterov(X, Y, t, k_max):\n",
    "    s = X.shape\n",
    "    m = s[1]\n",
    "    beta_cur = np.zeros(m)\n",
    "    for k in range(1, k_max):\n",
    "        beta_prev = beta_cur\n",
    "        z_k = beta_cur + (k - 1) / (k + omega) * (beta_cur - beta_prev)\n",
    "        XTX_z_k = np.dot(X.T, (Y - np.dot(X, z_k)))\n",
    "        beta_cur = z_k + t * XTX_z_k\n",
    "        # print(np.linalg.norm(Y - np.dot(X, beta_cur)))\n",
    "        if np.linalg.norm(Y - np.dot(X, beta_cur)) <= delta:\n",
    "            break\n",
    "    return beta_cur, k+1\n",
    "\n",
    "def Nesterov_debias(X, Y, t, k_max):\n",
    "    s = X.shape\n",
    "    m = s[1]\n",
    "    beta_cur = np.zeros(m)\n",
    "    for k in range(1, k_max+1):\n",
    "        beta_prev = beta_cur\n",
    "        z_k = beta_cur + (k - 1) / (k + omega) * (beta_cur - beta_prev)\n",
    "        XTX_z_k = np.dot(X.T, (Y - np.dot(X, z_k)))\n",
    "        beta_cur = z_k + t * XTX_z_k\n",
    "        if k == k_max:\n",
    "            break\n",
    "    return beta_cur\n",
    "\n",
    "beta_Nesterov, k_Nesterov = Nesterov(X, Y, t, max_iter)\n",
    "beta_Nesterov_debias = Nesterov_debias(X, X@beta_Nesterov, t, k_Nesterov)\n",
    "beta_Nesterov_debias = 2*beta_Nesterov - beta_Nesterov_debias\n",
    "norm_Nesterov = np.linalg.norm(beta_Nesterov - beta)\n",
    "norm_Nesterov_debias = np.linalg.norm(beta_Nesterov_debias - beta)\n",
    "print(norm_Nesterov, k_Nesterov, norm_Nesterov_debias)\n",
    "sigma_Nesterov = np.linalg.norm(Y - np.dot(X, beta_Nesterov))\n",
    "sigma_Nesterov = sigma_Nesterov / np.sqrt(s2)\n",
    "print(sigma_Nesterov)\n",
    "sigma_Nesterov_debias = np.linalg.norm(Y - np.dot(X, beta_Nesterov_debias))\n",
    "sigma_Nesterov_debias = sigma_Nesterov_debias / np.sqrt(s2)\n",
    "print(sigma_Nesterov_debias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.496383433513028 1241 7.6901385262639\n",
      "1.2147691424072888\n",
      "0.5346641945262842\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import gamma\n",
    "\n",
    "# 分数阶回归\n",
    "t        = 5e-4     # 步长\n",
    "max_iter = 2000      # 最大迭代次数\n",
    "theta    = 1.8       # theta\n",
    "A        = np.zeros((max_iter+1, max_iter+1))\n",
    "B        = np.zeros((max_iter, max_iter+1))\n",
    "g        = 1/gamma(theta)\n",
    "k1       = t**(theta)/(theta*(theta+1))\n",
    "k2       = t**(theta)/theta\n",
    "\n",
    "for k in range(max_iter):\n",
    "    for j in range(k+2):\n",
    "        if j == 0:\n",
    "            d = k**(theta+1)-(k-theta)*(k+1)**(theta)\n",
    "            A[j, k+1] = k1*d\n",
    "        elif j < k+1:\n",
    "            d = (k-j+2)**(theta+1)+(k-j)**(theta+1)-2*(k-j+1)**(theta+1)\n",
    "            A[j, k+1] = k1*d\n",
    "        elif j == k+1:\n",
    "            A[j, k+1] = k1 \n",
    "    for i in range(k+1):\n",
    "        if i < k+1:\n",
    "            d = (k-i+1)**theta-(k-i)**theta  \n",
    "            B[i, k+1] = k2*d\n",
    "\n",
    "\n",
    "def Frac(X, Y, k_max):\n",
    "    s  = X.shape\n",
    "    m  = s[1]\n",
    "    b  = np.zeros((m, k_max+1))  \n",
    "    bp = np.zeros((m, k_max+1))\n",
    "    for k in range(1, k_max):\n",
    "        bp[:, k+1] = g*sum([B[j, k+1]*np.dot(X.T, (Y - np.dot(X, b[:,j]))) for j in range(1,k+1)]) \n",
    "        b[:, k+1]  = g*(A[k+1, k+1]*np.dot(X.T, (Y - np.dot(X, bp[:,k+1])))+sum([A[j, k+1]*np.dot(X.T, (Y - np.dot(X, b[:,j]))) for j in range(1, k+1)]))\n",
    "        beta_cur   = b[:, k+1]\n",
    "        if np.linalg.norm(Y - np.dot(X, beta_cur)) <= delta:\n",
    "            break\n",
    "    return beta_cur, k\n",
    "def Frac_debias(X, Y, k_max):\n",
    "    s  = X.shape\n",
    "    m  = s[1]\n",
    "    b  = np.zeros((m, k_max+1))  \n",
    "    bp = np.zeros((m, k_max+1))\n",
    "    for k in range(1, k_max):\n",
    "        bp[:, k+1] = g*sum([B[j, k+1]*np.dot(X.T, (Y - np.dot(X, b[:,j]))) for j in range(1,k+1)]) \n",
    "        b[:, k+1]  = g*(A[k+1, k+1]*np.dot(X.T, (Y - np.dot(X, bp[:,k+1])))+sum([A[j, k+1]*np.dot(X.T, (Y - np.dot(X, b[:,j]))) for j in range(1, k+1)]))\n",
    "        beta_cur   = b[:, k+1]\n",
    "        if k == k_max:\n",
    "            break\n",
    "    return beta_cur\n",
    "\n",
    "beta_Frac, k_Frac = Frac(X, Y, max_iter)\n",
    "beta_Frac_debias = Frac_debias(X, X@beta_Frac, k_Frac+1)\n",
    "beta_Frac_debias = 2*beta_Frac - beta_Frac_debias\n",
    "norm_Frac = np.linalg.norm(beta_Frac - beta)\n",
    "norm_Frac_debias = np.linalg.norm(beta_Frac_debias - beta)\n",
    "print(norm_Frac, k_Frac, norm_Frac_debias)\n",
    "sigma_Frac = np.linalg.norm(Y - np.dot(X, beta_Frac))\n",
    "sigma_Frac = sigma_Frac / np.sqrt(s2)\n",
    "print(sigma_Frac)\n",
    "sigma_Frac_debias = np.linalg.norm(Y - np.dot(X, beta_Frac_debias))\n",
    "sigma_Frac_debias = sigma_Frac_debias / np.sqrt(s2)\n",
    "print(sigma_Frac_debias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS                   & 43.2172 &  ~    &  ~            \\\\\n",
      "SC                   & 7.7426 &  ~    &  9.9797   \\\\\n",
      "Lasso                & 35.9007 &  ~    &  ~                \\\\\n",
      "Ridge                & 34.2867 &  ~    &  32.2905    \\\\\n",
      "Landweber            & 10.3824   &  7482 &  8.7730   \\\\\n",
      "Showalter            & 10.3819   &  7484 &  8.7724   \\\\\n",
      "HBF                  & 6.9123   &  2611  &  7.0552  \\\\\n",
      "$\\textrmAR^\\kappa$ & 10.3234   &  589  &  8.7054   \\\\\n",
      "SOAR                 & 8.1805   &  1225  &  7.0530  \\\\\n",
      "Nesterov             & 10.3821   &  7484 &  8.7727  \\\\\n",
      "FAR                  & 9.4964   &  1241  &  7.6901   \\\\   \\hline\n"
     ]
    }
   ],
   "source": [
    "print(f\"LS                   & {norm_LS:.4f} &  ~    &  ~            \\\\\\\\\")\n",
    "print(f\"SC                   & {norm_cut:.4f} &  ~    &  {norm_cut_debias:.4f}   \\\\\\\\\")\n",
    "print(f\"Lasso                & {norm_Lasso:.4f} &  ~    &  ~                \\\\\\\\\")\n",
    "print(f\"Ridge                & {norm_Ridge:.4f} &  ~    &  {norm_Ridge_debias:.4f}    \\\\\\\\\")\n",
    "print(f\"Landweber            & {norm_Landweber:.4f}   &  {k_Landweber} &  {norm_Landweber_debias:.4f}   \\\\\\\\\")\n",
    "print(f\"Showalter            & {norm_showalter:.4f}   &  {k_showalter} &  {norm_showalter_debias:.4f}   \\\\\\\\\")\n",
    "print(f\"HBF                  & {norm_hbf:.4f}   &  {k_hbf}  &  {norm_hbf_debias:.4f}  \\\\\\\\\")\n",
    "print(f\"$\\\\textrmAR^\\\\kappa$ & {norm_ARk:.4f}   &  {k_ARk}  &  {norm_ARk_debias:.4f}   \\\\\\\\\")\n",
    "print(f\"SOAR                 & {norm_second:.4f}   &  {k_second}  &  {norm_second_debias:.4f}  \\\\\\\\\")\n",
    "print(f\"Nesterov             & {norm_Nesterov:.4f}   &  {k_Nesterov} &  {norm_Nesterov_debias:.4f}  \\\\\\\\\")\n",
    "print(f\"FAR                  & {norm_Frac:.4f}   &  {k_Frac}  &  {norm_Frac_debias:.4f}   \\\\\\\\   \\\\hline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
