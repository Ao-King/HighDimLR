{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "条件数: 98.46354442674601\n"
     ]
    }
   ],
   "source": [
    "# 生成随机矩阵X_n\n",
    "n = 1000    # 样本量\n",
    "p = 1000    # 变量数\n",
    "\n",
    "# 创建协方差矩阵\n",
    "cov_matrix = np.full((p, p), 0.5)  # 创建一个所有元素都是 0.5 的矩阵\n",
    "np.fill_diagonal(cov_matrix, 2.0)  # 将对角线元素设置为 2.0\n",
    "\n",
    "mean_vector                = np.zeros(p)  # 均值向量\n",
    "X                          = np.random.multivariate_normal(mean_vector, cov_matrix, n)\n",
    "# 奇异值分解\n",
    "U, S, Vt = np.linalg.svd(X)\n",
    "\n",
    "# 计算条件数\n",
    "condition_number = S[0] / S[-1]\n",
    "print(\"条件数:\", condition_number)\n",
    "\n",
    "# 打印奇异值\n",
    "# S_adjusted = np.copy(S)\n",
    "# for i in range(len(S)):\n",
    "#         S_adjusted[i] /= 10**(0.00225*i)   # 或者选择其他缩放因子\n",
    "# print(\"最大奇异值:\", np.max(S_adjusted))\n",
    "# print(\"最小奇异值:\", np.min(S_adjusted))\n",
    "# print(\"条件数:\", np.max(S_adjusted)/np.min(S_adjusted))\n",
    "# Sigma = np.zeros((U.shape[0], Vt.shape[0]))\n",
    "# np.fill_diagonal(Sigma, S_adjusted)\n",
    "# X =  U @ Sigma @ Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   4   78  192  291  301  306  454  534  635  640  709  776  817  823\n",
      "  846  948 1119 1147 1250 1341]\n"
     ]
    }
   ],
   "source": [
    "# 定义β向量\n",
    "beta = np.zeros(p)  # 初始化β向量为0\n",
    "\n",
    "# 根据条件设置β向量的值\n",
    "beta[0:5]   = 2.0   # βi = 2.0, i = 1, 2, 3, 4, 5\n",
    "beta[5:10]  = -2.0  # βi = -2.0, i = 6, 7, 8, 9, 10\n",
    "beta[10:15] = 1.0   # βi = 1.0, i = 11, 12, 13, 14, 15\n",
    "beta[15:20] = -1.0  # βi = -1.0, i = 16, 17, 18, 19, 20\n",
    "# beta[20:25] = 5.0   # βi = 5.0, i = 21, 22, 23, 24, 25\n",
    "\n",
    "# Generate 20 random indices\n",
    "indices = np.random.randint(low=0, high=p, size=20)\n",
    "\n",
    "# Get the indices of non-zero elements in beta\n",
    "nonzero_indices = np.nonzero(beta)[0]\n",
    "\n",
    "# print(nonzero_indices)\n",
    "\n",
    "# 初始化random_beta为零向量\n",
    "random_beta = np.zeros(p)\n",
    "\n",
    "# Assign the non-zero elements randomly\n",
    "# 此处假设的意图是将beta中的非零元素随机分配到random_beta中\n",
    "# 但这样的操作逻辑上存在问题，因为indices的长度和nonzero_indices可能不同\n",
    "# 为了简化，这里我们只是简单地复制beta到random_beta\n",
    "random_beta[indices] = beta[nonzero_indices]\n",
    "\n",
    "# Print the randomly assigned beta\n",
    "# print(random_beta)\n",
    "beta = random_beta\n",
    "nonzero_indices = np.nonzero(beta)[0]\n",
    "print(nonzero_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = Vt.T @ Vt @ beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.75012571858161\n"
     ]
    }
   ],
   "source": [
    "# 生成均值为0方差为4的n维向量en\n",
    "mean    = 0  # 均值\n",
    "std_dev = 2  # 标准差，方差为标准差的平方，即4\n",
    "\n",
    "# 生成向量\n",
    "e = np.random.normal(mean, std_dev, n)\n",
    "norm_e = np.linalg.norm(e)\n",
    "Y = np.dot(X, beta) + e\n",
    "print(norm_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau   = 1\n",
    "delta = tau*norm_e\n",
    "s1, s2 = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.797995245748872\n",
      "2.4734865018731572e-14\n"
     ]
    }
   ],
   "source": [
    "# 最小二乘法\n",
    "def least_square(X, Y):\n",
    "    beta = np.linalg.lstsq(X, Y, rcond=None)[0]\n",
    "    return beta\n",
    "beta_LS = least_square(X, Y)\n",
    "norm_LS = np.linalg.norm(beta_LS - beta)\n",
    "print(norm_LS)\n",
    "sigma_LS = np.linalg.norm(Y - np.dot(X, beta_LS))\n",
    "sigma_LS = sigma_LS / np.sqrt(s2)\n",
    "print(sigma_LS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of C that minimizes the mean squared error is: 131100\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "C = 200000\n",
    "m = 100\n",
    "def compute_mse(c, X, Y):\n",
    "    alpha = c / s1\n",
    "    I = np.eye(s2)\n",
    "    beta_r = np.linalg.inv(X.T @ X + alpha * I) @ X.T @ Y\n",
    "    mse = np.linalg.norm(beta_r - beta)\n",
    "    return mse\n",
    "\n",
    "# 假设 X, Y, C 已经定义\n",
    "mse_list = Parallel(n_jobs=-1)(delayed(compute_mse)(c, X, Y) for c in range(0, C + 1, m))\n",
    "\n",
    "best_c = np.argmin(mse_list)*m\n",
    "print(\"The value of C that minimizes the mean squared error is:\", best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.593042635195277 4.6573841549331805\n",
      "0.5824834669608071\n",
      "0.1621471153397847\n"
     ]
    }
   ],
   "source": [
    "# 岭回归\n",
    "def ridge(X, Y, C):\n",
    "    alpha  = C/s1\n",
    "    I      = np.eye(s2)\n",
    "    gen    = np.linalg.inv(X.T @ X + alpha*I) @ X.T\n",
    "    beta   = gen @ Y\n",
    "    beta_debias = (I + alpha*np.linalg.inv(X.T @ X + alpha*I))@beta\n",
    "    gen_debias  = (I + alpha*np.linalg.inv(X.T @ X + alpha*I))@gen\n",
    "    return beta, beta_debias, gen, gen_debias\n",
    "\n",
    "beta_Ridge, beta_Ridge_debias, gen_Ridge, gen_Ridge_debias = ridge(X, Y, best_c)\n",
    "norm_Ridge = np.linalg.norm(beta_Ridge - beta)\n",
    "norm_Ridge_debias = np.linalg.norm(beta_Ridge_debias - beta)\n",
    "print(norm_Ridge, norm_Ridge_debias)\n",
    "sigma_Ridge = np.linalg.norm(Y - np.dot(X, beta_Ridge))\n",
    "sigma_Ridge = sigma_Ridge / np.sqrt(s2)\n",
    "print(sigma_Ridge)\n",
    "sigma_Ridge_debias = np.linalg.norm(Y - np.dot(X, beta_Ridge_debias))\n",
    "sigma_Ridge_debias = sigma_Ridge_debias / np.sqrt(s2)\n",
    "print(sigma_Ridge_debias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9630165839947535 1740 4.7394313726118895\n",
      "1.5882680978563277\n",
      "0.9657833862100805\n"
     ]
    }
   ],
   "source": [
    "# Landweber回归\n",
    "t        = 5e-7    # 步长\n",
    "max_iter = 10000   # 最大迭代次数\n",
    "\n",
    "def landweber(X, Y, t, max_iter):\n",
    "    s = X.shape\n",
    "    m = s[1]\n",
    "    beta_cur = np.zeros(m)\n",
    "    for k in range(1, max_iter):\n",
    "        beta_prev = beta_cur\n",
    "        beta_cur = beta_prev + t * np.dot(X.T, (Y - np.dot(X, beta_prev)))\n",
    "        if np.linalg.norm(Y - np.dot(X, beta_cur)) <= delta:\n",
    "            break\n",
    "    return beta_cur, k\n",
    "def landweber_debias(X, Y, t, max_iter):\n",
    "    s = X.shape\n",
    "    m = s[1]\n",
    "    beta_cur = np.zeros(m)\n",
    "    for k in range(1, max_iter):\n",
    "        beta_prev = beta_cur\n",
    "        beta_cur = beta_prev + t * np.dot(X.T, (Y - np.dot(X, beta_prev)))\n",
    "        if k == max_iter:\n",
    "            break\n",
    "    return beta_cur\n",
    "beta_Landweber, k_Landweber = landweber(X, Y, t, max_iter)\n",
    "beta_Landweber_debias = landweber_debias(X, Y, t, 2*k_Landweber)\n",
    "norm_Landweber    = np.linalg.norm(beta_Landweber - beta)\n",
    "norm_Landweber_debias  = np.linalg.norm(beta_Landweber_debias - beta)  \n",
    "\n",
    "print(norm_Landweber, k_Landweber, norm_Landweber_debias)\n",
    "sigma_Landeweber = np.linalg.norm(Y - np.dot(X, beta_Landweber))\n",
    "sigma_Landeweber = sigma_Landeweber / np.sqrt(s2)\n",
    "print(sigma_Landeweber)\n",
    "sigma_Landeweber_debias = np.linalg.norm(Y - np.dot(X, beta_Landweber_debias))\n",
    "sigma_Landeweber_debias = sigma_Landeweber_debias / np.sqrt(s2)\n",
    "print(sigma_Landeweber_debias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
